{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8Uf2WkVphD7s",
        "m4vfwZ25hots",
        "Rr14-rvSh9-n",
        "jZ2tyRWVjpWW",
        "eUppLFzrkDip"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Uf2WkVphD7s"
      },
      "source": [
        "#installing Dependencies "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYOmtCzhg-p9",
        "outputId": "e2520286-e957-4f80-c903-a8c8350669ac"
      },
      "source": [
        "!pip -q install trax\n",
        "\n",
        "!pip install termcolor\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 637 kB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX_xeLEr7KM9",
        "outputId": "4fd687d0-a118-4174-b903-4ecd949f69da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWfW7fNGhlAY"
      },
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import trax\n",
        "from trax import layers as tl\n",
        "from trax.supervised import training\n",
        "from termcolor import colored"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4vfwZ25hots"
      },
      "source": [
        "#Acessing the DATA path and vocab file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SKh0iUAhtJ5"
      },
      "source": [
        "# filename of the MultiWOZ dialogue dataset\n",
        "DATA_FILE = 'data.json'\n",
        "# data directory\n",
        "DATA_DIR = '/content/drive/MyDrive/Colab Notebooks/NLP/MULTIWOZ2 2'\n",
        "# dictionary where we will load the dialogue dataset\n",
        "DIALOGUE_DB = {}\n",
        "#Vocab dir\n",
        "VOCAB_DIR = '/content/drive/MyDrive/Colab Notebooks/NLP/vocab'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuKySJcDhykn",
        "outputId": "fbdf8dc1-dc73-4329-c564-b0171fe95f57"
      },
      "source": [
        "# help function to load a JSON file\n",
        "def load_json(directory, file):\n",
        "    with open(f'{directory}/{file}') as file: \n",
        "        db = json.load(file)\n",
        "    return db\n",
        "\n",
        "# load the dialogue data set into our dictionary\n",
        "multiwoz_json = load_json(DATA_DIR, DATA_FILE)\n",
        "\n",
        "print(\"Dataset loaded. Number of dialogues: {}\".format(len(multiwoz_json)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded. Number of dialogues: 10438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tScSLiQ8mBNp",
        "outputId": "3d650102-95dc-4218-8895-f777ec7c2723"
      },
      "source": [
        "print(multiwoz_json['SNG01856.json'].keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['goal', 'log'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHTn9llqh3z2",
        "outputId": "7a8221f2-1344-4a51-a62d-6fa0a36fd9fc"
      },
      "source": [
        "## Displayed a dialogue with colors\n",
        "\n",
        "sample_dialogue = multiwoz_json['SNG0129.json']['log']\n",
        "\n",
        "for i in range(len(sample_dialogue)):\n",
        "    if i % 2 == 0:\n",
        "        print(colored(sample_dialogue[i]['text'], 'blue'))\n",
        "    else:\n",
        "        print(colored(sample_dialogue[i]['text'], 'red'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34mHello, I have been robbed.  Can you please help me get in touch with the police?\u001b[0m\n",
            "\u001b[31mParkside Police Station is in Parkside, Cambridge. Their number is 01223358966. Anything else I can do for you?\u001b[0m\n",
            "\u001b[34mCan I please have the postcode as well?\u001b[0m\n",
            "\u001b[31mThe postcode for the Parkside Police Station is CB11JG. Can I help you with anything else?\u001b[0m\n",
            "\u001b[34mWas Parkside the address of the police station? If not, can I have the address please?\u001b[0m\n",
            "\u001b[31mYes, Parkside is the address.\u001b[0m\n",
            "\u001b[34mThank you that will be all for now.\u001b[0m\n",
            "\u001b[31mGreat. Thank you for contacting Cambridge Towninfo Centre.\u001b[0m\n",
            "\u001b[34mYou were great. Goodbye.\u001b[0m\n",
            "\u001b[31mWe are happy to help. Have a good day!\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Piwg-H6Gkxkp",
        "outputId": "ac8b2b0a-b183-441d-84fd-00c68a91a5d8"
      },
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP/MULTIWOZ2 2/README.json') as file:\n",
        "    print(file.read())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#####################################################\n",
            "#####################################################\n",
            "#  Copyright Cambridge Dialogue Systems Group, 2018 #\n",
            "#####################################################\n",
            "#####################################################\n",
            "\n",
            "Dataset contains the following json files:\n",
            "1. data.json: the woz dialogue dataset, which contains the conversation  users and wizards, as well as a set of coarse labels for each user turn. Files with multi-domain dialogues have \"MUL\" in their names. Single domain dialogues have either \"SNG\" or \"WOZ\" in their names.\n",
            "2. restaurant_db.json: the Cambridge restaurant database file, containing restaurants in the Cambridge UK area and a set of attributes.\n",
            "3. attraction_db.json: the Cambridge attraction database file, contining attractions in the Cambridge UK area and a set of attributes.\n",
            "4. hotel_db.json: the Cambridge hotel database file, containing hotels in the Cambridge UK area and a set of attributes.\n",
            "5. train_db.json: the Cambridge train (with artificial connections) database file, containing trains in the Cambridge UK area and a set of attributes.\n",
            "6. hospital_db.json: the Cambridge hospital database file, contatining information about departments.\n",
            "7. police_db.json: the Cambridge police station information.\n",
            "8. taxi_db.json: slot-value list for taxi domain.\n",
            "9. valListFile.json: list of dialogues for validation.\n",
            "10. testListFile.json: list of dialogues for testing.\n",
            "11. system_acts.json:\n",
            "  There are 6 domains ('Booking', 'Restaurant', 'Hotel', 'Attraction', 'Taxi', 'Train') and 1 dummy domain ('general').\n",
            "  A domain-dependent dialogue act is defined as a domain token followed by a domain-independent dialogue act, e.g. 'Hotel-inform' means it is a 'inform' act in Hotel domain.\n",
            "  Dialogue acts which cannot take slots, e.g., 'good bye', are defined under 'general' domain.\n",
            "  A slot-value pair defined as a list with two elements. The first element is slot token and the second one is its value.\n",
            "  If a dialogue act takes no slots, e.g., dialogue act 'offer booking' for an utterance 'would you like to take a reservation?', its slot-value pair is ['none', 'none']\n",
            "  There are four types of value:\n",
            "  1) If a slot takes binary value, e.g., 'has Internet' or 'has park', the value is either 'yes' or 'no'.\n",
            "  2) If a slot is under the act 'request', e.g., 'request' about 'area', the value is express as '?'.\n",
            "  3) The value that appears in the utterancem e,g., the name of a restaurant.\n",
            "  4) If for some reasons the turn does not have annotation then it is labeled as \"No Annotation\".\n",
            "12. ontology.json: Data-based ontology.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr14-rvSh9-n"
      },
      "source": [
        "##Data Pre-Processing\n",
        "\n",
        "----\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzJimD3JiAfM"
      },
      "source": [
        "dialogue_sentences_list = []\n",
        "\n",
        "for json_index in multiwoz_json.keys():\n",
        "    \n",
        "    dialogue = multiwoz_json[json_index]['log']\n",
        "\n",
        "    dialogue_sentences_str = \"\"\n",
        "\n",
        "    for i in range(len(dialogue)):\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            dialogue_sentences_str += \" Person 1: \" + dialogue[i]['text']\n",
        "        else:\n",
        "            dialogue_sentences_str += \" Person 2: \" + dialogue[i]['text']\n",
        "    \n",
        "    dialogue_sentences_list.append(dialogue_sentences_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMuU32j5mNhp",
        "outputId": "85b7e55f-7228-439f-c229-b18042fb7fd8"
      },
      "source": [
        "print(len(dialogue_sentences_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuoG63BviE7Y",
        "outputId": "0c2fa7cc-4ca4-47d3-ce9d-a2c4b948ef6f"
      },
      "source": [
        "## shuffle the list\n",
        "random.shuffle(dialogue_sentences_list)\n",
        "\n",
        "## Split 500 dialogues to the test dataset\n",
        "train_data, test_data = dialogue_sentences_list[:-500], dialogue_sentences_list[-500:]\n",
        "\n",
        "print(\"Number of train_data: {}\".format(len(train_data)))\n",
        "print(\"Number of test_data: {}\".format(len(test_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of train_data: 9938\n",
            "Number of test_data: 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erbbHz9niL-2",
        "outputId": "1c6ee7cb-c5ea-4d3d-aa65-88f5c6e1e3b7"
      },
      "source": [
        "print(train_data[0])\n",
        "for i in train_data[0:5]:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Person 1: i need a place to stay Person 2: Sure, do you have an area of town you want to stay in? Person 1: I'd like to stay in the east.  I'm looking for a 4 star hotel.  I don't need any parking. Person 2: Okay, I recommend the Autumn House. It is a guest house in the cheap price range. Would you like me to book a reservation? Person 1: No, thank you.  Person 2: Can I help you with anything else? Person 1: Do you have any places that are hotels, not guest houses? Person 2: There aren't any 4 star hotels available in the east. Person 1: I guess I'll book the guesthouse for 4 people, 4 nights starting wednesday.  Person 2: I'm sorry, after taking a second look, the Autumn House is not located in the east area.  Would A&B Guest House be okay?  It's also 4-star. Person 1: Yes. Need it in the east. Star of 4 and do not care about parking, but do need it to be a hotel not guesthouse.  Person 2: I am sorry but there are no 4 star hotels in the east. Is there another area you would like to look at or possibly reserve the guesthouse? Person 1: Sorry, Im her husband, Ill take over the call, my wife is a little picky and confused.   Please book the guesthouse, 4 people, 4 nights starting wednesday.   Person 2: Okay that booking was successful and your reference number is SYX1AD7L. Person 1: Great!  I was also interested in finding a swimming pool in the north.  Person 2: Sure, Jesus Green Outdoor Pool is a nice one.  It is located between Victoria Road and the River. Person 1: What is the entrance fee? Person 2: I'm afraid I don't have that information available. Can I help you with anything else? Person 1: Yes, can I have the address and postcode, please? Person 2: Between Victoria Road and The River, cb43px. Would you like to know more about the place? Person 1: I need their entrance fee please Person 2: I'm afraid that I don't have that information. Can I help you with anything else? Person 1: If that information is not available, then that's all I need today. Person 2: Thank you for calling Cambridge TownInfo centre! It was a pleasure to help you, I hope you enjoy your time in Camridge!\n",
            " Person 1: i need a place to stay Person 2: Sure, do you have an area of town you want to stay in? Person 1: I'd like to stay in the east.  I'm looking for a 4 star hotel.  I don't need any parking. Person 2: Okay, I recommend the Autumn House. It is a guest house in the cheap price range. Would you like me to book a reservation? Person 1: No, thank you.  Person 2: Can I help you with anything else? Person 1: Do you have any places that are hotels, not guest houses? Person 2: There aren't any 4 star hotels available in the east. Person 1: I guess I'll book the guesthouse for 4 people, 4 nights starting wednesday.  Person 2: I'm sorry, after taking a second look, the Autumn House is not located in the east area.  Would A&B Guest House be okay?  It's also 4-star. Person 1: Yes. Need it in the east. Star of 4 and do not care about parking, but do need it to be a hotel not guesthouse.  Person 2: I am sorry but there are no 4 star hotels in the east. Is there another area you would like to look at or possibly reserve the guesthouse? Person 1: Sorry, Im her husband, Ill take over the call, my wife is a little picky and confused.   Please book the guesthouse, 4 people, 4 nights starting wednesday.   Person 2: Okay that booking was successful and your reference number is SYX1AD7L. Person 1: Great!  I was also interested in finding a swimming pool in the north.  Person 2: Sure, Jesus Green Outdoor Pool is a nice one.  It is located between Victoria Road and the River. Person 1: What is the entrance fee? Person 2: I'm afraid I don't have that information available. Can I help you with anything else? Person 1: Yes, can I have the address and postcode, please? Person 2: Between Victoria Road and The River, cb43px. Would you like to know more about the place? Person 1: I need their entrance fee please Person 2: I'm afraid that I don't have that information. Can I help you with anything else? Person 1: If that information is not available, then that's all I need today. Person 2: Thank you for calling Cambridge TownInfo centre! It was a pleasure to help you, I hope you enjoy your time in Camridge!\n",
            " Person 1: I want english food. Person 2: Please tell me the price range you would like today. Person 1: I don't care. Person 2: I'm sorry. There are no restaurants serving English food near your area. Person 1: How about Italian food then. Please give me phone number and postcode please. Person 2: Ask serves Italian food, is in the center of town and in the cheap price range. Their phone number is 01223 364917 and their postcode is C.B 2, 1 U.F. Person 1: thank you good bye Person 2: Thank you and good bye \n",
            " Person 1: I'm looking for a place to stay in west Cambridge. Person 2: i recommend hobsons house located in the west with a moderate price range and 3 star rated. it has both parking and internet. you can call them on 01223304906. postal address iscb39Ih, 96 barton road Person 1: I'm looking for a two star hotel with free wifi. Is there anything like that in the west? Person 2: I have no listings, maybe a different star rating? Person 1: Maybe I could stay in the north.  Can you please look there for a 2 star hotel that includes free wifi? Person 2: There are none matching your criteria, I have several 4 star ratings and 1 0 star rating.  Would any of these work for you? Person 1: Yes I want  to book it for 8 people and 3 nights starting from thursday Person 2: How about the Avalon?  It is a 4 star guesthouse.   Person 1: That sounds good can you book it for 3 nights for Thursday for 8 people. Person 2: Booking was successful. Reference number is : XGDP2O4H.is there anything else? Person 1: have you heard of cote? its a restaurant in town Person 2: Yes, Cote is a french restaurant, would you like me to make reservations for you? Person 1: no. i just want the address for today Person 2: Their address is Bridge Street City Centre.  Person 1: Thanks a lot, that's all for now.  Person 2: Can I look up any other information for you? Person 1: No, thank you. You've been very helpful. Person 2: You're welcome, have a great day!\n",
            " Person 1: I would like to find a restaurant in the centre.  Person 2: There are several good restaurant options in that area. Is there a specific type of food you are looking for? Person 1: I need it to be in the expensive price range. What are my options? Person 2: There are quite few expensive places there with many food types from african to turkish. Perhaps you would like local food - there are several expensive british restaurants. Person 1: Lets go with the Turkish one. Can I get the address and postcode please? Person 2: The address is 196 Mill Road City Centre, postcode cb13nf. Person 1: Thanks for the information. Goodbye. Person 2: Enjoy your meal at the Meze Bar Restaurant. Goodbye.\n",
            " Person 1: Hello, I am looking for a restaurant in any area that serves danish food.  Person 2: I'm sorry but there is no matching records found that fits your requests . Person 1: what about international food?  Person 2: There are three restaurants that serve international food. Would you like a specific price range? Person 1: I do not have a preference.  Person 2: bloomsbury restaurant is in the centre and serving international food and it is a moderate price is there anything I can help you with? Person 1: Can I get the phone number and postcode, please? Person 2: bloomsbury restaurant's phone number is 0871 942 9180, their postcode is C.B 2, 3 D.T Person 1: Thank you bye bye Person 2: Have a nice day! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8CZSqX2mVwQ",
        "outputId": "4c033200-dc1d-4cf4-d17a-1f61e6dc6c87"
      },
      "source": [
        "print(test_data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Person 1: Can you help me find some entertainment in Cambridge? Person 2: There are many things to do in Cambridge; clubs, museums, churches, boating etc. What would you like to do?  Person 1: I don't care but I need the area, entrance fee, and postcode of entertainment available in town. Person 2: I'd recommend All Saints Church in the centre. Their postcode is cb58bs and they have free entrance. Anything else I can help you with? Person 1: Yes, I am looking for a place to dine.  Can you recommend a restaurant in the expensive price range that serves Swiss food? Person 2: I'm sorry, there are no Swiss restaurants in the area.  Do you have another kind in mind that I could assist with? Person 1: How about British food? Person 2: I have several restaurants which serve British food in different areas of the town. Is there an area you prefer? Person 1: I'm sorry I did not want British food.  Are there any chinese restaurants instead located in the centre area? Person 2: Yes, I have found 4. Ugly duckling, tang chinese, hk fusion and sesame restaurant and bar. Would you like any of these? Person 1: Which is your favorite? Can you get me the address, postcode, and phone number? I'll give them a call myself.  Person 2: i would recommend the sesame restaurant and bar the address is 17 Hills Road City Centre, cb21nw. phone number is 01223358899. is there anything else i can assist with? Person 1: No that is all. Thank you. Person 2: You're welcome. Have a great day!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDmreqzqiOS2"
      },
      "source": [
        "for i in range(len(train_data)):\n",
        "    train_data[i] = train_data[i].strip()\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    test_data[i] = test_data[i].strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHfjZSwfiYKL"
      },
      "source": [
        "#Building DATA Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCfTTmodic-F"
      },
      "source": [
        "def stream_generator(data):\n",
        "    while True:\n",
        "        x = random.choice(data)\n",
        "        yield (x, x)\n",
        "\n",
        "VOCAB_DIR = '/content/drive/MyDrive/Colab Notebooks/NLP/vocab'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLni8TgqijRl"
      },
      "source": [
        "data_pipeline = trax.data.Serial(trax.data.Shuffle(),\n",
        "                                 trax.data.Tokenize(vocab_file = 'en_32k.subword'),\n",
        "                                 trax.data.FilterByLength(2048),\n",
        "                                 trax.data.BucketByLength(boundaries = [128, 256, 512, 1024], batch_sizes = [16, 8, 4, 2, 1]),\n",
        "                                 trax.data.AddLossWeights(id_to_mask = 0))\n",
        "\n",
        "train_stream = data_pipeline(stream_generator(train_data))\n",
        "test_stream = data_pipeline(stream_generator(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJf27XNwim4n",
        "outputId": "f394c07b-0eaf-4cc2-ee6d-bfc9ca0071e5"
      },
      "source": [
        "# (input, target, weights)\n",
        "print(\"train_stream\")\n",
        "print(next(train_stream))\n",
        "print(\"\\ntest_stream\")\n",
        "print(next(test_stream))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_stream\n",
            "(array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32))\n",
            "\n",
            "test_stream\n",
            "(array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0],\n",
            "       [8745,    3,   54, ...,    0,    0,    0]]), array([[1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.],\n",
            "       [1., 1., 1., ..., 0., 0., 0.]], dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqTok4kjir2M",
        "outputId": "d7f97858-3648-4b75-e5ae-dc9a6d771d85"
      },
      "source": [
        "## Check\n",
        "x = next(train_stream)[0]\n",
        "y = next(test_stream)\n",
        "\n",
        "print(x.shape)\n",
        "y = trax.data.detokenize(x[0], vocab_file = 'en_32k.subword')\n",
        "print(y)\n",
        "del x, y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4, 512)\n",
            "Person 1: Let's find me a cheap eatery in the north part of the town. Thank you. Person 2: There are 2 places in the north that are in the cheap price range.  Royal Spice which serves Indian food and Da Vinci Pizzeria.  Do either sound good to you? Person 1: Royal Spice sounds good.  Can you reserve a table for 2 at 17:45 on Sunday? Person 2: Sure reference number is CH9ZLEFO Person 1: I also need a place to stay Person 2: Could you tell me what area you would like to stay in, and if you require parking or wifi? Person 1: I want somewhere with 0 stars and free wifi that is cheap and in the north, just like my restaurant Person 2: I have found the City Centre North B and B guesthouse.  It is cheap and has 0 stars. Person 1: Can you tell me the postcode? Person 2: Sure. The postcode is cb43ht. Can I help you with anything else today? Person 1: I'm going to need a taxi also. Person 2: Okay, please tell me where you will depart from, your destination, and a time that you either wish to leave or arrive by Person 1: The hotel to the restaurant.... Person 2: The taxi booking has been completed! Look out for a yellow bmw the contact number is 07132659323. Anything else I can assist with today?  Person 1: That does it for now, thank you. Person 2: Great.  Thanks for talking to us!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpOe0FppiuLY"
      },
      "source": [
        "#Create The Re-Former Model\n",
        "\n",
        "##Initiate Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ2GyoZli2VL",
        "outputId": "01780699-2e4c-4161-fb4b-61a997760bc8"
      },
      "source": [
        "def ReformerLM(vocab_size = 33000, n_layers = 6, mode = 'train', attention_type = tl.SelfAttention):\n",
        "    model = trax.models.reformer.ReformerLM(vocab_size = vocab_size,\n",
        "                                            n_layers = n_layers,\n",
        "                                            mode = mode,\n",
        "                                            attention_type = attention_type)\n",
        "\n",
        "    return model\n",
        "\n",
        "## Check\n",
        "model = ReformerLM(mode = 'train')\n",
        "print(str(model))\n",
        "del model "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Serial[\n",
            "  Serial[\n",
            "    ShiftRight(1)\n",
            "  ]\n",
            "  Embedding_33000_512\n",
            "  Dropout\n",
            "  Serial[\n",
            "    PositionalEncoding\n",
            "  ]\n",
            "  Dup_out2\n",
            "  ReversibleSerial_in2_out2[\n",
            "    ReversibleHalfResidualDecoderAttn_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderFF_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        Serial[\n",
            "          FastGelu\n",
            "        ]\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderAttn_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderFF_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        Serial[\n",
            "          FastGelu\n",
            "        ]\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderAttn_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderFF_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        Serial[\n",
            "          FastGelu\n",
            "        ]\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderAttn_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderFF_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        Serial[\n",
            "          FastGelu\n",
            "        ]\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderAttn_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderFF_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        Serial[\n",
            "          FastGelu\n",
            "        ]\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderAttn_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "      ]\n",
            "      SelfAttention\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "    ReversibleHalfResidualDecoderFF_in2_out2[\n",
            "      Serial[\n",
            "        LayerNorm\n",
            "        Dense_2048\n",
            "        Dropout\n",
            "        Serial[\n",
            "          FastGelu\n",
            "        ]\n",
            "        Dense_512\n",
            "        Dropout\n",
            "      ]\n",
            "    ]\n",
            "    ReversibleSwap_in2_out2\n",
            "  ]\n",
            "  Concatenate_in2\n",
            "  LayerNorm\n",
            "  Dropout\n",
            "  Serial[\n",
            "    Dense_33000\n",
            "  ]\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNG-Nh1njILA"
      },
      "source": [
        "def training_loop(ReformerLM, train_generator, eval_generator):\n",
        "    # schedule of the learning rate\n",
        "    lr_schedule = trax.lr.warmup_and_rsqrt_decay(n_warmup_steps = 4000, max_value = 0.001)\n",
        "\n",
        "    # the training task\n",
        "    train_task = training.TrainTask(labeled_data = train_generator,\n",
        "                                    loss_layer = tl.CrossEntropyLoss(),\n",
        "                                    optimizer = trax.optimizers.Adam(0.001),\n",
        "                                    lr_schedule = lr_schedule,\n",
        "                                    n_steps_per_checkpoint = 50)#Change the steps size --original was 200\n",
        "    \n",
        "    # the evaluation task\n",
        "    eval_task = training.EvalTask(labeled_data = eval_generator,metrics = [tl.CrossEntropyLoss(), tl.Accuracy()])\n",
        "    \n",
        "    # create the loop object\n",
        "    loop = training.Loop(model = ReformerLM(mode = 'train'),tasks = [train_task],\n",
        "                         eval_tasks = [eval_task],output_dir = '/content/drive/MyDrive/ReF-MODEL') #/content/drive\n",
        "    \n",
        "    return loop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs9Z8SJOuMWH"
      },
      "source": [
        "#SEE Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eaeF2pem8Py"
      },
      "source": [
        "## This box needs to be executed if training_loop has been run before 55555\n",
        "#!rm model.pkl.gz\n",
        "#!rm config.gin\n",
        "#!rm -r train\n",
        "#!rm -r eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEkl8ICqrwjb",
        "outputId": "0619b753-98c8-42f2-ef1b-d60393f038a2"
      },
      "source": [
        "loop = training_loop(ReformerLM, train_stream, test_stream)\n",
        "loop.run(20000) # taking almost 75 minutes to run 200   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/jax/_src/lib/xla_bridge.py:413: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  \"jax.host_count has been renamed to jax.process_count. This alias \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Step    900: Ran 25 train steps in 805.37 secs\n",
            "Step    900: train CrossEntropyLoss | -122.80056000\n",
            "Step    900: eval  CrossEntropyLoss | -129.02351379\n",
            "Step    900: eval          Accuracy |  0.07477289\n",
            "\n",
            "Step    925: Ran 25 train steps in 665.25 secs\n",
            "Step    925: train CrossEntropyLoss | -132.05345154\n",
            "Step    925: eval  CrossEntropyLoss | -135.43891907\n",
            "Step    925: eval          Accuracy |  0.07008670\n",
            "\n",
            "Step    950: Ran 25 train steps in 541.31 secs\n",
            "Step    950: train CrossEntropyLoss | -141.64566040\n",
            "Step    950: eval  CrossEntropyLoss | -147.44853210\n",
            "Step    950: eval          Accuracy |  0.06678082\n",
            "\n",
            "Step    975: Ran 25 train steps in 537.52 secs\n",
            "Step    975: train CrossEntropyLoss | -152.55732727\n",
            "Step    975: eval  CrossEntropyLoss | -151.58013916\n",
            "Step    975: eval          Accuracy |  0.06196999\n",
            "\n",
            "Step   1000: Ran 25 train steps in 543.35 secs\n",
            "Step   1000: train CrossEntropyLoss | -163.88581848\n",
            "Step   1000: eval  CrossEntropyLoss | -166.85350037\n",
            "Step   1000: eval          Accuracy |  0.07307693\n",
            "\n",
            "Step   1025: Ran 25 train steps in 543.45 secs\n",
            "Step   1025: train CrossEntropyLoss | -175.07841492\n",
            "Step   1025: eval  CrossEntropyLoss | -177.45742798\n",
            "Step   1025: eval          Accuracy |  0.06234818\n",
            "\n",
            "Step   1050: Ran 25 train steps in 547.74 secs\n",
            "Step   1050: train CrossEntropyLoss | -186.95272827\n",
            "Step   1050: eval  CrossEntropyLoss | -193.10342407\n",
            "Step   1050: eval          Accuracy |  0.05747801\n",
            "\n",
            "Step   1075: Ran 25 train steps in 539.53 secs\n",
            "Step   1075: train CrossEntropyLoss | -200.84017944\n",
            "Step   1075: eval  CrossEntropyLoss | -213.41073608\n",
            "Step   1075: eval          Accuracy |  0.06824147\n",
            "\n",
            "Step   1100: Ran 25 train steps in 548.61 secs\n",
            "Step   1100: train CrossEntropyLoss | -214.30717468\n",
            "Step   1100: eval  CrossEntropyLoss | -222.82775879\n",
            "Step   1100: eval          Accuracy |  0.05750605\n",
            "\n",
            "Step   1125: Ran 25 train steps in 552.60 secs\n",
            "Step   1125: train CrossEntropyLoss | -229.20683289\n",
            "Step   1125: eval  CrossEntropyLoss | -238.23155212\n",
            "Step   1125: eval          Accuracy |  0.05559515\n",
            "\n",
            "Step   1150: Ran 25 train steps in 560.27 secs\n",
            "Step   1150: train CrossEntropyLoss | -242.95362854\n",
            "Step   1150: eval  CrossEntropyLoss | -254.15917969\n",
            "Step   1150: eval          Accuracy |  0.06553756\n",
            "\n",
            "Step   1175: Ran 25 train steps in 562.68 secs\n",
            "Step   1175: train CrossEntropyLoss | -259.21649170\n",
            "Step   1175: eval  CrossEntropyLoss | -264.56307983\n",
            "Step   1175: eval          Accuracy |  0.05619335\n",
            "\n",
            "Step   1200: Ran 25 train steps in 567.33 secs\n",
            "Step   1200: train CrossEntropyLoss | -275.52267456\n",
            "Step   1200: eval  CrossEntropyLoss | -288.85614014\n",
            "Step   1200: eval          Accuracy |  0.05597723\n",
            "\n",
            "Step   1225: Ran 25 train steps in 566.99 secs\n",
            "Step   1225: train CrossEntropyLoss | -293.40408325\n",
            "Step   1225: eval  CrossEntropyLoss | -299.62985229\n",
            "Step   1225: eval          Accuracy |  0.06739278\n",
            "\n",
            "Step   1250: Ran 25 train steps in 562.55 secs\n",
            "Step   1250: train CrossEntropyLoss | -310.50061035\n",
            "Step   1250: eval  CrossEntropyLoss | -320.89654541\n",
            "Step   1250: eval          Accuracy |  0.05997393\n",
            "\n",
            "Step   1275: Ran 25 train steps in 549.03 secs\n",
            "Step   1275: train CrossEntropyLoss | -330.45831299\n",
            "Step   1275: eval  CrossEntropyLoss | -339.14031982\n",
            "Step   1275: eval          Accuracy |  0.05778717\n",
            "\n",
            "Step   1300: Ran 25 train steps in 555.95 secs\n",
            "Step   1300: train CrossEntropyLoss | -350.98211670\n",
            "Step   1300: eval  CrossEntropyLoss | -360.36779785\n",
            "Step   1300: eval          Accuracy |  0.05430464\n",
            "\n",
            "Step   1325: Ran 25 train steps in 558.15 secs\n",
            "Step   1325: train CrossEntropyLoss | -370.43508911\n",
            "Step   1325: eval  CrossEntropyLoss | -374.39398193\n",
            "Step   1325: eval          Accuracy |  0.06335616\n",
            "\n",
            "Step   1350: Ran 25 train steps in 559.64 secs\n",
            "Step   1350: train CrossEntropyLoss | -392.26617432\n",
            "Step   1350: eval  CrossEntropyLoss | -405.45690918\n",
            "Step   1350: eval          Accuracy |  0.06403622\n",
            "\n",
            "Step   1375: Ran 25 train steps in 563.80 secs\n",
            "Step   1375: train CrossEntropyLoss | -416.22686768\n",
            "Step   1375: eval  CrossEntropyLoss | -425.85913086\n",
            "Step   1375: eval          Accuracy |  0.06744868\n",
            "\n",
            "Step   1400: Ran 25 train steps in 557.01 secs\n",
            "Step   1400: train CrossEntropyLoss | -439.62448120\n",
            "Step   1400: eval  CrossEntropyLoss | -456.24456787\n",
            "Step   1400: eval          Accuracy |  0.06143128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZ2tyRWVjpWW"
      },
      "source": [
        "#Model EVALUATION \n",
        "\n",
        "####Helper Function to De-tokenize \n",
        "####To print Coloured Dialogue"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9k-xdJ2jXwA"
      },
      "source": [
        "#####################################################################################3\n",
        "#!rm -f model/model.pkl.gz  #Location:/content/model/model.weights.npy.gz #/content/model/model.pkl.gz\n",
        "#/content/model.pkl.gz\n",
        "#loop = training_loop(ReformerLM, train_stream, test_stream)\n",
        "#loop.run(20000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km85bpUWjvGq"
      },
      "source": [
        "def tokenize(sentence):\n",
        "    return list(trax.data.tokenize(iter([sentence]), vocab_file = 'en_32k.subword'))[0]\n",
        "\n",
        "def detokenize(tokens):\n",
        "    return trax.data.detokenize(tokens, vocab_file = 'en_32k.subword')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcvTwZIAj3uA"
      },
      "source": [
        "## The helper function to print out the dialogues in colors\n",
        "\n",
        "def print_colored_dialogue(dialogues):\n",
        "    result = []\n",
        "    cur_conversation = \"\"\n",
        "    first_sentence_printed = False\n",
        "    Person1_turn = True\n",
        "    for s in dialogues:\n",
        "        cur_conversation += s        # model predicts Person 2 finishes the sentence\n",
        "        if cur_conversation.endswith(\"Person 1: \"):\n",
        "            if not first_sentence_printed:\n",
        "                first_sentence_printed = True\n",
        "            else:\n",
        "                # print everything before \"Person 1: \"\n",
        "                print(colored(\"Person 2: \" + cur_conversation.split(\"Person 1: \")[0].strip(), 'red'))\n",
        "                cur_conversation = \"\"\n",
        "                Person1_turn = True\n",
        "\n",
        "        # model predicts Person 1 finished the sentence\n",
        "        elif cur_conversation.endswith(\"Person 2: \"):\n",
        "            # print everything before \"Person 2: \"\n",
        "            print(colored(\"Person 1: \" + cur_conversation.split(\"Person 2: \")[0].strip(), 'blue'))\n",
        "            cur_conversation = \"\"\n",
        "            Person1_turn = False\n",
        "\n",
        "    # print remaining sentences\n",
        "    if Person1_turn:\n",
        "        print(colored(\"Person 1: \" + cur_conversation, 'blue'))\n",
        "    else:\n",
        "        print(colored(\"Person 2: \" + cur_conversation, 'red'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2OHmx6bkAbF"
      },
      "source": [
        "# grab a batch from test_stream\n",
        "test_x, test_y, test_w = next(test_stream)\n",
        "print(\"Batch_size = {}\".format(test_x.shape[0]))\n",
        "\n",
        "# choose the first example\n",
        "sample_x = test_x[0][None, :]\n",
        "\n",
        "print(\"\\nInput dialogue:\")\n",
        "print_colored_dialogue(detokenize(sample_x[0]))\n",
        "\n",
        "pred = loop.eval_model(sample_x)\n",
        "pred_token = pred.argmax(axis = -1)\n",
        "\n",
        "print(\"\\nOutput dialogue:\")\n",
        "print_colored_dialogue(detokenize(pred_token[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzZxWflhkDDM"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUppLFzrkDip"
      },
      "source": [
        "#Real TEST\n",
        "#Real Test!!!!!!!!\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UlA9DN4kKFo"
      },
      "source": [
        "def generate_next_token(current_tokens, model):\n",
        "\n",
        "    \"\"\"\n",
        "    Generate the next token\n",
        "    \n",
        "    Inputs\n",
        "            current_tokens: <list of int> currently generated token so far\n",
        "            model: <trax model> the model for the prediction\n",
        "    \n",
        "    Output\n",
        "            next_token: <int> the next token generated by the model\n",
        "    \"\"\"\n",
        "\n",
        "    # number of tokens generated so far\n",
        "    current_tokens_length = len(current_tokens)\n",
        "   \n",
        "    # find the next power of 2 to be the final length after padding\n",
        "    final_padded_length = 2**int(np.ceil(np.log2(current_tokens_length + 1)))\n",
        "\n",
        "    # caucluate the number of zeros to pad\n",
        "    to_pad_length = final_padded_length - current_tokens_length\n",
        "\n",
        "    # padding\n",
        "    padded_current_tokens = np.array(current_tokens.tolist() + [0 for _ in range(to_pad_length)])[None, :]\n",
        "\n",
        "    # use the model to predict the log probabilities of the next token\n",
        "    model_output, _ = model((padded_current_tokens, padded_current_tokens))\n",
        "\n",
        "    # (note) model_output has shape (batch_size, len_of_whole_token_list, vocab_size)\n",
        "    # only take the log probability distribution of the last token\n",
        "    next_token_logprob = model_output[0, current_tokens_length, :]\n",
        "\n",
        "    # select the token with the largest log probability\n",
        "    next_token = int(np.argmax(next_token_logprob))\n",
        "\n",
        "    return next_token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU8pFdYBkTbT"
      },
      "source": [
        "def extend_dialogue(current_dialogue, model, maximum_number_extension = 100):\n",
        "    current_tokens_list = tokenize(current_dialogue)\n",
        "\n",
        "    num_tokens_generated = 0\n",
        "\n",
        "    while num_tokens_generated <= maximum_number_extension:\n",
        "        # given current_tokens_list, generate the next token\n",
        "        next_output_token = generate_next_token(current_tokens_list, model)\n",
        "\n",
        "        current_tokens_list = current_tokens_list.tolist()\n",
        "\n",
        "        current_tokens_list.append(next_output_token)\n",
        "\n",
        "        current_tokens_list = np.array(current_tokens_list)\n",
        "\n",
        "        num_tokens_generated += 1\n",
        "\n",
        "    # maximum number of tokens reached, output the detokenized dialogue\n",
        "    complete_dialogue = trax.data.detokenize(current_tokens_list, vocab_file = 'en_32k.subword')\n",
        "\n",
        "    return complete_dialogue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqAvHx95kWP_"
      },
      "source": [
        "## Example wehre Person 1 asks for an avocado for no reason\n",
        "\n",
        "dialogue_seed = \"Person 1: Um... Can I have some avocado? Person 2: \"\n",
        "\n",
        "complete_dialogue = extend_dialogue(dialogue_seed, loop.eval_model, maximum_number_extension = 100)\n",
        "\n",
        "print_colored_dialogue(complete_dialogue)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}